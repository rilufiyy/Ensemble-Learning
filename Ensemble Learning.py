# -*- coding: utf-8 -*-
"""Sri Lutfiya Dwiyeni_Assignment Ensemble Learning_AIML 8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-D_hvdUXM3MfhT3LpZLl8-dUCRrhT8oR

# Reflection Questions
1. Setelah membangun model ensemble, menurutmu mengapa pendekatan ensemble (seperti Random Forest atau Gradient Boosting) sering memberikan hasil yang lebih stabil dibanding satu model tunggal? Jelaskan berdasarkan pengalamanmu mengerjakan case study ini.

    Jawab: Berdasarkan case study mengenai student performance yang saya olah menggunakan regresi, pendekatan ensemble lebih stabil karena menggabungkan banyak model, sehingga kesalahan satu model dapat ditutupi oleh model lainnya. Hal ini terlihat jelas dari hasil cross-validation secara menyeluruh di semua model yang digunakan. Berikut merupakan rincian proses evaluasi model:
      
     * Decision Tree model biasa menunjukkan variasi skor CV yang paling besar, yaitu dengan MAE_std 0.0077 lebih tinggi dibandingkan model DT yang menggunakan bagging, RMSE_std 0.01018, dan R^2_std 0.0110 paling tidak stabil. Hal tersebut menunjukkan bahwa Decision Tree sangat sensitif terhadap perubahan kecil pada data, sehingga skor tiap fold bisa berubah cukup jauh. Hal ini merupakan ciri model dengan varians yang tinggi.
     * Random Forest bagging model memiliki variansi turun yang signifikan, shingga model tersebut jauh lebih stabil, dengan MAE_std nya yaitu 0.0088, RMSE_std nya yaitu 0.01345, dan R^_std nya yaitu 0.00556 turun sekitar 50% dari model Decision Tree. Model tersebut variansinya tetap jauh lebih kecil dari model tunggal. Hal ini karena Random Forest membangun banyak pohon pada data bootstrap, dimana noise setiap pohon saling menetralkan.
     * Decision Tree Bagging memiliki stabilitas terbaik di antara metode bagging yang ada, dengan score MAE_std nya yaitu 0.00509 paling stabil dari seluruh model bagging, RMSE_std yaitu 0.00923, dan R^2_std 0.00479. Hal ini membuktikan bahwa menggabungkan banyak Decision Tree membuat prediksi lebih konsisten dibanding hanya satu Decision Tree saja.
     * Gradient Boosting model stabil modelnya dan memiliki tingkat akurasi yang tinggi, dengan MAE_std nya yaitu 0.00767, RMSE_std 0.01128, dan R^2_std 0.00455. Meskipun sedikit lebih tinggi dari Bagging, Boosting tetap sangat stabil dan akurat karena model tersebut memperbaiki error secara bertahap.
     * Stacking memiliki stabilitas terbaik secara keseluruhan, dengan R^2_std nya yaitu 0.00324 paling rendah dibandingkan dengan semua model yang saya gunakan, RMSE_std 0.00808, dan MAE_std 0.00690. Stacking memanfaatkan banyak model sekaligus, shingga prediksi akhir lebih bagus dan tidak mudah bias meskipun data berubah sedikit.
  
    Secara keseluruhan, dapat disimpulkan bahwa ensemble lebih stabil karena dapat menurunkan variansi model melalui kombinasi prediksi. Dibuktikan dengan adanya model decision tree tunggal memiliki variance tertinggi, sedangkan untuk bagging, boosting, dan stacking memiliki variansi jauh lebih rendah. Stacking menjadi model paling stabil karena RE^2_std nya paling kecil yaitu 0.0032. Hal ini membuktikan bahwa ensemble tidak mudah goyah meskipun data training berubah sedikit>

2. Dalam proses membandingkan Bagging, Boosting, dan Stacking, model mana yang menurutmu memberikan generalisasi terbaik? Apa faktor teknis yang menurutmu paling mempengaruhi stabilitas performa model ensemble tersebut.

    Jawab: Berdasarkan hasil cross validasi dan grafik evaluasi final verdict, generalisai terbaik ada pada stacking dan gradient boosting model. Kedua model tersebut berada pada posisi teratas baik dari sisi akurasi maupun stabilitas. Dengan rincian cross validasi sebagai berikut:
    * Gradient Boosting model memiliki MAE_mean sebesar 0.1440 terendah dari semua model, RMSE_mean 0.1866 terendah, sama dengan Stacking, R^2_mean 0.95823, dimana ini sangat tinggi dan stabil, serta R^2_std yaitu 0.00455 sangat stabil. Hal tersebut menunjukkan bahwa Gradient Boosting model sangat konsisten, akurat dalam prediksi, dan memiliki error paling kecil.
    * Stacking memiliki MAE_mean yaitu 0.1498 sedikit di atas Boosting, RMSE_mean 0.1866, R^2_mean 0.95827 paling tertinggi dari semua model, dan R^2_std 0.00324 memiliki stabilitas terbaik atau bisa dikatakan bahwa variansi paling rendah. Dari hal tersebut terlihat bahwa Stacking memberikan generalisasi yang sangat baik, bahkan R^2 nya sedikit lebih tinggi daripada Gradient Boosting.
    * Untuk perbandingan dengan Bagging Random forest dan bagged tree, random forest memiiliki R^2_mean nya itu 0.93734, turun signifikan dibandingkan dengan Boosting dan Stacking, memiliki performa yang bagus, tetapi tidak setinggi dua model terbaik. Sedangkan untuk Decision Tree Bagging memiliki R^2_mean 0.94581 lebih baik dari Random Forest, namun tetap masih di bawah Boosting dan Stacking.
    * Sehingga Boosting dan Stacking adalah model dengan generalisasi terbaik pada case study ini, dimana Stacking unggul pada R^2 dan Boosting unggul pada MAE.

    Untuk faktor teknis yang memengaruhi stabilitas model ensemble di antaranya yaitu:
    1. Bias Variance Trade-off
      * Bagging menurunkan varians stabil, hal ini terbukti dari R^2_std kecil pada bagging
      * Boosting menurunkan bias secara bertahap, dengan akurasi tinggi yang diindikasikan oleh MAE Boosting paling rendah.
      * Stacking mengombinasikan pola model berbeda, meningkatkan generaliisasi dan stabilitas model yang ditandai dengan R^2_std paling kecil.
    2. Metode sampling atau bobot error
      * Untuk Bagging menggunakan bootstrap, dimana setiap pohon berbeda sehingga varians dapat menurun.
      * Untuk Boosting memberi bobot lebih besar pada error, hal ini untuk memperbaiki kesalahan secara iteratif guna menurunkan bias, sehingga hasil prediksi lebih presisi.
    3. Kompleksitas model dasar
      * Pohon tunggal Decision Tree model terlalu dalam, sehingga menyebabkan model menjadi overfitting, hal ini terbukti dari R^2_std terbesar yaitu sekitar 0.0110.
      * Boosting menggunakan pohon dangkal, dan hasilnya jauh lebih stabil.
      * Stacking bisa tidak stabil kalau base learner terlalu kompleks, tetapi pada model yang saya gunakan, base learner modelnya lebih optimal, shingga Stacking paling stabil di antara semua model yang saya gunakan.
    4. Hyperparameter tuning
      * Dengan menggunakan Gradient Boosting memiliki learning rate kecil dan banyak estimators, sehingga model tersebut menghasilkan performa terbaik dan stabil.
      * Random forest model bisa stabil jika jumlah pohon yang digunakan banyak, hal ini terlihat dari MAE dan RMSE yang cukup konsisten.

    Oleh karena itu dari semua model yang saya gunakan dapat disimpulkan bahwa Boosting dan Stacking adalah model dengan generalisasi terbaik, dengan keunggulan tipis jika dilihat dari metrik yang dievaluasi di akhir. Dengan Gradient Boosting memberikan error paling rendah yang ditandai dengan MAE dan RMSE terbaik, serta Stacking memberikan R^2 paling tinggi dan variansi paling kecil, sehingga Stacking memiliki stabilitas terbaik dari semua model yang saya gunakan pada prediksi student performance dengan target GPA.

# Import Libraries
"""

!pip install xgboost

import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import StackingRegressor

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

from xgboost import XGBRegressor

import warnings
warnings.filterwarnings('ignore')

"""# Load Dataset"""

df = pd.read_csv('/content/Student_performance_data _.csv')
df

"""# Data Preprocessing (Data Wrangling)

## Missing Values and Duplicate Handling
"""

df.info()

"""**Penjelasan insight:** setelah dilakukannya pengecekan missing value, tidak ditemukan adanya missing value pada dataset student performance."""

df.duplicated().sum()

"""**Penjelasan insight:** Setelah dilakukannya pengecekan duplikasi pada dataset student performance. Dataset tersebut tidak terindikasi adanya duplikat data yang ditandai dengan (0) saat pengecekan duplicate menggunakan sum duplicate."""

x = df.drop(["StudentID", "GPA"], axis=1)
y = df["GPA"]

x.head()

x.describe()

"""## Categorical Data"""

x_categorical = x
for i in x_categorical:
    print(f'the number of unique values in {i} is {x[i].nunique()}')

x_categorical = x_categorical.drop(['StudyTimeWeekly','Absences'],axis=1)
x_categorical.head()

x_categorical['Gender'] = x_categorical['Gender'].replace({0:'Male',1:'Female'})
x_categorical['Ethnicity'] = x_categorical['Ethnicity'].replace({0:'Caucasian', 1:'African American', 2:'Asian', 3:'Other'})
x_categorical['ParentalEducation'] = x_categorical['ParentalEducation'].replace({0:'None', 1:'High School', 2:'College', 3:'Bachelor\'s', 4:'Higher'})
x_categorical['Tutoring'] = x_categorical['Tutoring'].replace({0:'No',1:'Yes'})
x_categorical['ParentalSupport'] = x_categorical['ParentalSupport'].replace({0:'None', 1:'Low', 2:'Moderate', 3:'High', 4:'Very High'})
x_categorical['Extracurricular'] = x_categorical['Extracurricular'].replace({0:'No',1:'Yes'})
x_categorical['Sports'] = x_categorical['Sports'].replace({0:'No',1:'Yes'})
x_categorical['Music'] = x_categorical['Music'].replace({0:'No',1:'Yes'})
x_categorical['Volunteering'] = x_categorical['Volunteering'].replace({0:'No',1:'Yes'})
x_categorical['GradeClass'] = x_categorical['GradeClass'].replace({0:'Very Low',1:'Low',2:'Medium',3:'High',4:'Very High'})

categorical_cols = [
    'Gender', 'Ethnicity', 'ParentalEducation', 'Tutoring',
    'ParentalSupport', 'Extracurricular', 'Sports', 'Music', 'GradeClass', 'Volunteering'
]

x[categorical_cols] = x[categorical_cols].astype('object')

x_categorical

x_categorical_encoded = pd.get_dummies(x_categorical, drop_first=True)
x_categorical_encoded

encoding_columns = x_categorical_encoded.columns
encoding_columns

"""## Numerical Data"""

x_numerical = x.select_dtypes(include="number")
numerical_columns = x_numerical.columns

num_scaler = StandardScaler()
x_numerical_scaled = num_scaler.fit_transform(x_numerical)
x_numerical_scaled

"""## Combined Data"""

x_numerical_scaled = pd.DataFrame(x_numerical_scaled, columns=x_numerical.columns)
x_numerical_scaled

x_processed = pd.concat([x_numerical_scaled, x_categorical_encoded], axis=1)
x_processed

x_numerical = x.select_dtypes(include="number")
numerical_columns = x_numerical.columns

x_categorical = x.select_dtypes(exclude="number")
categorical_columns = x_categorical.columns

def preprocess_data(new_data):
    new_num = new_data.select_dtypes(include="number")
    new_num_scaled = pd.DataFrame(
        num_scaler.transform(new_num),
        columns=new_num.columns
    )

    new_cat = new_data.select_dtypes(exclude="number")
    new_cat_encoded = pd.get_dummies(new_cat, drop_first=True)

    new_cat_encoded = new_cat_encoded.reindex(columns=encoding_columns, fill_value=False)

    processed = pd.concat([new_num_scaled.reset_index(drop=True),
                           new_cat_encoded.reset_index(drop=True)], axis=1)

    return processed

x_processed = preprocess_data(x)
x_processed

x_processed = pd.DataFrame(x_processed)

"""## With Scikit-learn transformer pipeline"""

from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

def create_preprocessor():
  numerical_imputer = SimpleImputer(strategy='median')
  numerical_scaler = MinMaxScaler()
  numerical_transformer = Pipeline(
      steps=[
          ('imputer', numerical_imputer),
          ('scaler', numerical_scaler)
      ]
  )


  categorical_imputer = SimpleImputer(strategy='constant', fill_value='missing')
  categorical_encoder = OneHotEncoder()
  categorical_transformer = Pipeline(
      steps=[
          ('imputer', categorical_imputer),
          ('encoder', categorical_encoder),
      ]
  )

  preprocessor = ColumnTransformer(
      transformers=[
          ('numerical', numerical_transformer, numerical_columns),
          ('categorical', categorical_transformer, categorical_columns),
      ]
  )

  return preprocessor

preprocessor = create_preprocessor()

preprocessor.fit(x)
x_processed = preprocessor.transform(x)

preprocessor

"""# Exploratory Data Analysis (EDA)"""

fig, axes = plt.subplots(4, 3, figsize=(16, 14), constrained_layout=True)
axes = axes.flatten()

for i, col in enumerate(x_categorical.columns.drop(['GradeClass'])):
    sns.countplot(data=x_categorical, x=col, ax=axes[i], palette="viridis")
    axes[i].set_title(f'Distribution of {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Count')

"""**Penjelasan insight:** Berdasarkan grafik visualisasi di atas, diperoleh bahwa:
1. Untuk kolom Age memiliki distribusi umur yang cukup merata antara 15-18 tahun dan usia 15 tahun sedikit lebih banyak dibanding lainnya.
2. Untuk kolom Gender, jumlah distribusi antara female dan male nya hampir sama, tidak ada dominasi yang signifikan. Dataset seimbang berdasarkan gender, hal tersebut bagus untuk menghindari bias.
3. Untuk kolom Ethnicity mayoritas siswa adalah Caucasian, minoritasnya adalah other jumlahnya paling sedikit. Data ini menunjukkan ketidakseimbangan etknis, yang mungkin berdampak pada analisis fairness.
4. Pada kolom Parental Education mayoritas orang tua berpendidikan College atau High School, pendidikan Higher jumlahnya paling sedikit. Distribusi tersebut menunjukkan dominasi pendidikan menengah, bukan tinggi.
5. Pada kolom Tutoring, lebih banyak siswa yang tidak mengikuti tutoring dibandingkan yang ikut, hal ini bisa menunjukkan faktor eksternal belajar rendah pada sebagian besar siswa.
6. Pada kolom Parental Support, dukungan kategori terbanyak yaitu Moderate dan High, dukungan Very High dan None cenderung lebih sedikit. Artinya mayoritas siswa mendapat dukungan dari orang tua yang cukup baik.
7. Untuk Kolom Extracurricular, siswa yang tidak ikut extracurricular lebih banyak dari yang ikut. Hal ini bisa menggambarkan aktivitas luar kelas yang rendah.
8. Untuk kolom Sport, siswa mayoritas tidak ikut olahraga, pola pada fitur ini mirip seperti extracurricular.
9. Pada kolom Music, sebagian besar siswa tidak ikut kegiatan musik, hal ini menunjukkan minat terhadapt musik extracurricular cukup rendah.
10. Pada kolom Volunteering, jumlah yang tidak volunteering sangat dominan, siswa yang terlibat dalam kegiatan sosial sangat dikit.
"""

x['StudyTimeWeekly'] = np.ceil(x['StudyTimeWeekly'])
corr = x.corr()
plt.figure(figsize=(12,10))
sns.heatmap(corr, cmap='magma', annot=True, fmt='.2f')

"""**Penjelasan insight:** Berdasarkan Heatmap correlation di atas diperoleh bahwa:
1. Korelasi kuat yang penting di antaranya ialah:
    * Absences dengan GradeClass, dengan skor korelasinya sebesar 0.73. Artinya semakin banyak ketidakhadiran, maka semakin rendah pula nilai atau grade seorang siswa, hal ini merupakan faktor paling kuat yang menjelaskan performa akademik siswa.
    * Fitur StudyTimWeekly dengan GradeClass memiliki skor korelasi -0.13, korelasinya lemah negatif namun dapat mengedintifikasikan bahwa semakin kurang waktu belajar, maka nilai cenderung sedikit menurun. Walau korelasi antar dua fitur tersebut kecil, tetapi masih relevan sebagai faktor pendukung.
2. Korelasi lemah di hampir semua variabel lain di antaranya ialah:
    * Gender, Ethnicity, dan Age, dari ketiga fitur tersebut memiliki korelasi sangat kecil terhadap GradeClass.
    * Extracurricular, Sports, Music, dan Volunteering hampir tidak berpengaruh.
    * Pada fitur ParentalEducation dan ParentalSupport juga memiliki korelasi yang cenderung lemah.
    * Hal tersebut berarti faktor sosial ataupun demografis tidak dominan dalam mempengaruhi nilai siswa.
3. Tidak ada korelasi negatif yang kuat, yaitu:
    * Semua korelasi negatif sangat kecil berdasarkan fitur-fitur yang dilihat dari heatmap correlation.
    * Tidak ada variabel yang berpengaruh buruk secara signifikan selain ketidakhadiran.
4. Variabel-variabel saling tidak berkorelasi tinggi satu sama lain, di antaranya yaitu:
    * Hampir semua nilai korelasi antar fitur berada di sekitar 0.00 hingga 0.05.
    * Hal ini berarti fitur dataset tidak redundant, sehingga jarang terjadi multicollinearity dan model machine learning dapat terbantu karena fitur tidak saling overlap satu sama lain.
5. High-level summary, yaitu:
    * Fitur Absences adalah prediktor terkuat untuk performa akademik siswa.
    * Faktor lain punya pengaruh sangat kecil.
    * Dataset cenderung bebas multicollinearity.
    * Waktu belajar punya sedikit pengaruh, namun jauh lebih kecil dibandingkan dengan absensi.

## Data Splitting
"""

x_train, x_test, y_train, y_test = train_test_split(
    x_processed, y, test_size=0.2, random_state=42
)

x_valid, x_test, y_valid, y_test = train_test_split(
    x_test, y_test, test_size=0.5, random_state=42
)

"""# Modelling"""

model_tracker = {}

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

def evaluate_model(model, x_train, y_train, x_valid, y_valid, model_name):
    train_pred = model.predict(x_train)
    train_mae = mean_absolute_error(y_train, train_pred)
    train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
    train_r2 = r2_score(y_train, train_pred)

    valid_pred = model.predict(x_valid)
    valid_mae = mean_absolute_error(y_valid, valid_pred)
    valid_rmse = np.sqrt(mean_squared_error(y_valid, valid_pred))
    valid_r2 = r2_score(y_valid, valid_pred)

    print(f"\n{model_name} =====")
    print("Train MAE :", train_mae)
    print("Train RMSE:", train_rmse)
    print("Train R²  :", train_r2)
    print("-------------------------")
    print("Valid MAE :", valid_mae)
    print("Valid RMSE:", valid_rmse)
    print("Valid R²  :", valid_r2)

    return {
        "model": model,
        "train_mae": train_mae,
        "train_rmse": train_rmse,
        "train_r2": train_r2,
        "valid_mae": valid_mae,
        "valid_rmse": valid_rmse,
        "valid_r2": valid_r2
    }

def visualize_regression_metrics(model, x_train, y_train, x_valid, y_valid, model_name):
    y_pred = model.predict(x_valid)
    y_true = y_valid.values if hasattr(y_valid, "values") else y_valid

    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    r2 = r2_score(y_true, y_pred)

    print(f"\n{model_name} Results")
    print("MAE :", mae)
    print("RMSE:", rmse)
    print("R²  :", r2)


    fig, axes = plt.subplots(1, 3, figsize=(18, 5))


    axes[0].plot(y_true, label="Actual", linewidth=2)
    axes[0].plot(y_pred, label="Predicted", linewidth=2)
    axes[0].set_title("Actual vs Predicted")
    axes[0].set_xlabel("Sample Index")
    axes[0].set_ylabel("GPA")
    axes[0].legend()


    errors = y_pred - y_true
    axes[1].bar(range(len(errors)), errors)
    axes[1].set_title("Prediction Errors (y_pred - y_true)")
    axes[1].set_xlabel("Sample Index")
    axes[1].set_ylabel("Error")


    sns.kdeplot(y_true, ax=axes[2], label="Actual", linewidth=2)
    sns.kdeplot(y_pred, ax=axes[2], label="Predicted", linewidth=2)
    axes[2].set_title("Distribution Comparison")
    axes[2].set_xlabel("GPA")
    axes[2].legend()

    plt.suptitle(f"{model_name} Evaluation", fontsize=14)
    plt.tight_layout()
    plt.show()

    return {
        "MAE": mae,
        "RMSE": rmse,
        "R2": r2
    }

"""### Decision Tree"""

dt_model = DecisionTreeRegressor(
    max_depth=None,
    random_state=42
)

dt_model.fit(x_train, y_train)

model_tracker["Decision Tree"] = visualize_regression_metrics(
    dt_model, x_train, y_train, x_valid, y_valid, "Decision Tree"
)

"""**Penjelasan insight:** Berdasarkan grafik visualisasi setelah training model Decision Tree di atas, diperoleh beberapa insight di antaranya yaitu:
* Pada grafik Actual vs Predicted, terlihat bahwa model mampu mengikuti pola umum perubahan nilai GPA, tetapi garis prediksi masih sering tidak tepat menumpuk di atas nilai aktual. Hal ini menunjukkan bahwa meskipun model dapat menangkap arah besar variabilitas GPA, ia belum cukup akurat dalam memprediksi setiap sampel secara individual. Masih banyak titik di mana prediksi melenceng jauh dari nilai sebenarnya, menandakan bahwa kemampuan model dalam memahami hubungan antara fitur dan GPA belum optimal.

* Grafik Prediction Errors (y_pred - y_true) semakin menguatkan kesimpulan tersebut. Error tampak tersebar secara acak di sekitar nol, tetapi dengan penyebaran yang cukup lebar. Tidak tampak pola kecenderungan tertentu, model tidak terus-menerus overpredict atau underpredict, namun variasi error yang besar menunjukkan bahwa prediksi model masih kurang konsisten. Ini berarti tingkat ketepatan model terhadap GPA masih belum stabil dan performanya perlu ditingkatkan.

* Pada grafik Distribution Comparison, distribusi prediksi model tampak memiliki bentuk yang mirip dengan distribusi GPA aktual, tetapi masih terdapat perbedaan yang cukup jelas. Kurva prediksi terlihat sedikit bergeser dan lebih melebar dibandingkan distribusi aktual. Ini menunjukkan bahwa model mampu memahami pola distribusi GPA secara umum, tetapi belum dapat mereplikasi bentuk distribusi tersebut secara akurat. Artinya, model masih kurang sensitif terhadap pola-pola yang lebih detail dalam data GPA

## Baging Model

### Random Forest
"""

bagging_model = RandomForestRegressor(
    n_estimators=200,
    max_depth=None,
    max_features="sqrt",
    bootstrap=True,
    random_state=42
)

bagging_model.fit(x_train, y_train)

model_tracker["RandomForest"] = visualize_regression_metrics(
    bagging_model, x_train, y_train, x_valid, y_valid, "Random Forest (Bagging)"
)

"""**Penjelasan insight:** Berdasarkan grafik visualisasi dari training model Random Forest (bagging) di atas diperoleh beberapa insight di antaranya ialah sebagai berikut:
* Pada grafik Actual vs Predicted, terlihat bahwa Random Forest mampu menghasilkan prediksi yang secara umum mengikuti pola GPA aktual, tetapi tingkat kedekatannya belum sebaik Gradient Boosting. Garis prediksi berwarna oranye sering kali berada di sekitar nilai aktual, namun ada banyak titik di mana prediksi terlihat kurang presisi, terutama pada rentang nilai yang lebih tinggi atau lebih rendah. Pola prediksi cenderung lebih mengumpul pada nilai menengah, menandakan bahwa model sering memprediksi nilai aman di sekitar rata-rata, yang merupakan perilaku umum pada Bagging ketika variasi data cukup tinggi.

* Grafik Prediction Errors (y_pred - y_true) menunjukkan penyebaran error yang cukup variatif. Meskipun sebagian besar error berada di sekitar nol, ada beberapa prediksi dengan selisih cukup besar, menunjukkan bahwa model terkadang kesulitan menangkap pola tertentu dalam data. Error terlihat lebih acak dibandingkan model boosting, yang berarti Random Forest belum mampu benar-benar belajar pola kompleks dan malah lebih mengandalkan penghalusan prediksi dari banyak pohon. Tidak ada bias tertentu (misalnya selalu overpredict atau underpredict), tetapi amplitudo errornya masih cukup tinggi.

* Pada grafik Distribution Comparison, tampak bahwa distribusi prediksi GPA berwarna oranye cukup berbeda dari distribusi aktual biru. Kurva prediksi lebih tinggi dan lebih sempit di tengah, menandakan bahwa Random Forest banyak memusatkan prediksi pada nilai GPA tertentu, cenderung ke arah nilai rata-rata, sehingga variasi prediksi menjadi lebih kecil dibandingkan variasi aktual. Sementara itu, distribusi aktual memiliki ekor yang lebih lebar, menunjukkan keberadaan nilai ekstrem yang gagal ditangkap dengan baik oleh model. Perbedaan ini menunjukkan bahwa Random Forest belum mampu mempelajari distribusi data secara keseluruhan dan masih terlalu meratakan hasil prediksinya.

### Decision Tree Bagging
"""

bagging_model_dt = BaggingRegressor(
    estimator=DecisionTreeRegressor(),
    n_estimators=200, max_samples=0.7,
    bootstrap=True, random_state=42
)

bagging_model_dt.fit(x_train, y_train)

model_tracker["Decision Tree"] = visualize_regression_metrics(
    bagging_model_dt, x_train, y_train, x_valid, y_valid, "Decision Tree Bagging"
)

"""**Penjelasan insight:** Berdasarkan grafik visualisasi dari training model Decision Tree Bagging di atas diperoleh beberapa insight di antaranya ialah sebagai berikut:
* Pada grafik Actual vs Predicted, terlihat bahwa model Bagging dengan dasar Decision Tree mampu menangkap pola umum perubahan GPA, namun prediksinya masih terlihat cukup berantakan. Garis prediksi berwarna oranye sering kali tidak tepat menumpuk dengan garis aktual berwarna biru, terutama pada titik-titik ekstrem baik yang tinggi maupun rendah. Ini menunjukkan bahwa meskipun ensemble decision tree membantu mengurangi variansi dibandingkan single tree, model masih belum cukup presisi dalam memprediksi GPA pada masing-masing sampel. Dengan kata lain, pola besar berhasil ditangkap, tetapi akurasi individual masih kurang stabil.

* Grafik Prediction Errors (y_pred - y_true) mendukung temuan tersebut. Error model tersebar acak di sekitar nol, yang berarti model tidak memiliki bias kuat untuk selalu memprediksi terlalu tinggi atau terlalu rendah. Namun, rentang error cukup lebar, banyak nilai error yang berada di atas 0.5 atau di bawah -0.5. Penyebaran error yang cukup besar ini menunjukkan bahwa meskipun bagging mengurangi overfitting dibanding single tree, tingkat kesalahan prediksi GPA tetap cukup tinggi dan performa model belum konsisten di seluruh sampel.

* Terakhir, pada grafik Distribution Comparison, distribusi prediksi GPA terlihat mirip dengan distribusi GPA aktual, namun masih terdapat perbedaan bentuk yang cukup jelas. Distribusi prediksi sedikit lebih halus dan lebih melebar dibandingkan distribusi aktual, terutama pada area sekitar GPA 2–3. Hal ini menunjukkan bahwa model memahami pola distribusi global GPA secara keseluruhan, tetapi tidak dapat menangkap detail distribusi secara presisi. Dengan kata lain, model cukup baik dalam mempelajari gambaran besar, tetapi masih kurang sensitif terhadap variasi lokal dalam data.

## Boosting Model

### Boosting with Linier regression
"""

ada_hyperparams = {
    "n_estimators": 50,
    "learning_rate": 0.8
}

base_estimator = LinearRegression()

ada_model = AdaBoostRegressor(
    estimator=base_estimator,
    **ada_hyperparams,
    random_state=42
)

ada_model.fit(x_train, y_train)

model_tracker["AdaBoost"] = visualize_regression_metrics(
    ada_model, x_train, y_train, x_valid, y_valid, "AdaBoost"
)

"""**Penjelasan insight:** Berdasarkan grafik visualisasi dari training model Gradient Boosting di atas diperoleh beberapa insight di antaranya ialah sebagai berikut:
* Pada grafik Actual vs Predicted, terlihat bahwa model AdaBoost mampu mengikuti pola umum perubahan GPA, namun garis prediksinya masih sering tidak tepat menumpuk dengan nilai aktual. Prediksi cenderung lebih rapat dan terlihat lebih halus dibandingkan data sebenarnya, yang menunjukkan bahwa AdaBoost mencoba menstabilkan prediksi dari banyak weak learner. Meskipun demikian, masih banyak titik di mana nilai prediksi berbeda cukup jauh dari GPA aktual, terutama di area nilai yang ekstrem. Ini menandakan bahwa model memang lebih baik dalam menangani variasi dibandingkan single tree, tetapi tetap belum akurat untuk tiap sampel secara individual.

* Grafik Prediction Errors (y_pred − y_true) menunjukkan bahwa sebagian besar error berada dekat dengan angka nol, namun penyebarannya masih cukup besar. Ada banyak error kecil, tetapi beberapa titik menunjukkan error yang cukup signifikan, baik positif maupun negatif. Tidak tampak pola sistematis pada error, sehingga model tidak condong untuk selalu terlalu tinggi atau terlalu rendah dalam memprediksi GPA. Namun, adanya error yang tersebar cukup lebar menunjukkan bahwa performa model masih belum ideal dan prediksinya belum stabil sepenuhnya.

* Terakhir, grafik Distribution Comparison memperlihatkan bahwa distribusi prediksi GPA memiliki bentuk yang sangat mirip dengan distribusi GPA aktual. Kurva prediksi sedikit lebih rata dan tidak setinggi kurva aktual di bagian puncaknya, tetapi secara keseluruhan, bentuk distribusinya hampir sama. Ini menunjukkan bahwa AdaBoost cukup berhasil dalam menangkap distribusi global dari GPA. Namun, perbedaan halus pada puncak dan lebar kurva menunjukkan bahwa model masih kehilangan beberapa detail yang ada pada distribusi sebenarnya.

### Gradient Boosting
"""

gb_hyperparams = {
    "n_estimators": 300,
    "learning_rate": 0.05,
    "max_depth": 3
}

gb_model = GradientBoostingRegressor(
    **gb_hyperparams,
    random_state=42
)

gb_model.fit(x_train, y_train)

model_tracker["GradientBoosting"] = visualize_regression_metrics(
    gb_model, x_train, y_train, x_valid, y_valid, "Gradient Boosting"
)

"""**Penjelasan insight:** Berdasarkan grafik visualisasi dari training model Gradient Boosting di atas diperoleh beberapa insight di antaranya ialah sebagai berikut:
* Pada grafik Actual vs Predicted, terlihat bahwa model Gradient Boosting mampu memprediksi GPA dengan pola yang lebih stabil dibandingkan Bagging dan AdaBoost. Garis prediksi berwarna oranye terlihat lebih mengikuti alur nilai aktual berwarna biru, meskipun tetap ada beberapa bagian di mana prediksi melenceng cukup jauh, terutama pada titik dengan GPA yang sangat tinggi atau sangat rendah. Namun secara keseluruhan, prediksi Gradient Boosting tampak lebih rapi dan lebih dekat dengan nilai sebenarnya dibandingkan model-model sebelumnya, menunjukkan bahwa model ini lebih mampu menangkap hubungan yang kompleks dalam data GPA.

* Grafik Prediction Errors (y_pred - y_true) memperlihatkan bahwa sebagian besar error berada sangat dekat dengan angka nol. Meskipun masih ada error yang cukup besar pada beberapa sampel, penyebaran error terlihat lebih sempit dibandingkan Bagging atau AdaBoost. Ini menunjukkan bahwa prediksi Gradient Boosting lebih konsisten dan memiliki tingkat kesalahan yang lebih kecil secara umum. Tidak tampak pola khusus yang menunjukkan bias tertentu, sehingga model tidak cenderung terus-menerus memprediksi terlalu tinggi atau terlalu rendah.

* Pada grafik Distribution Comparison, distribusi prediksi GPA berwarna oranye sangat mirip dengan distribusi aktual berwarna biru. Bentuk kurva prediksi mengikuti puncak dan lebar distribusi aktual dengan cukup baik. Meski terdapat sedikit perbedaan pada bagian puncak, kurva prediksi sedikit lebih rendah, secara keseluruhan Gradient Boosting mampu meniru pola distribusi GPA secara akurat. Ini menandakan bahwa model tidak hanya belajar nilai rata-rata, tetapi juga mampu memahami karakteristik global dari distribusi data.

## Stacking Multiple Models
"""

base_models = [
    ("rf", RandomForestRegressor(
        n_estimators=200,
        max_depth=10,
        random_state=42
    )),
    ("gbr", GradientBoostingRegressor(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=3,
        random_state=42
    )),
    ("ada", AdaBoostRegressor(
        estimator=LinearRegression(),
        n_estimators=50,
        learning_rate=0.8,
        random_state=42
    ))
]


meta_model = LinearRegression()


stacking_model = StackingRegressor(
    estimators=base_models,
    final_estimator=meta_model,
    passthrough=True
)

stacking_model.fit(x_train, y_train)

model_tracker["Stacking"] = visualize_regression_metrics(
    stacking_model, x_train, y_train, x_valid, y_valid, "Stacking"
)

"""**Penjelasan insight:**  Berdasarkan grafik visualisasi dari training beberapa model menggunakan metode Stacking di atas diperoleh beberapa insight di antaranya ialah sebagai berikut:
* Pada grafik Actual vs Predicted, terlihat bahwa pola prediksi model Stacking mengikuti tren nilai GPA asli dengan cukup baik, meskipun masih ada beberapa titik yang menyimpang. Garis prediksi berwarna oranye cenderung menempel pada garis aktualberwarna biru, menandakan bahwa model berhasil menangkap pola umum hubungan antar-fitur untuk memprediksi GPA secara stabil. Meskipun tidak sempurna, sebaran keduanya yang berdekatan menunjukkan bahwa Stacking memberikan estimasi yang relatif konsisten dibandingkan model tunggal seperti Decision Tree.

* Grafik Prediction Errors menunjukkan bahwa sebagian besar error berada sangat dekat dengan angka nol, tanda bahwa deviasi prediksi terhadap nilai aktual kecil dan model cukup akurat. Distribusi error yang lebih rapat dan jarang menyentuh nilai ekstrem menggambarkan bahwa Stacking lebih mampu mengurangi kesalahan ekstrim dibandingkan model lain seperti AdaBoost atau Decision Tree. Hal ini menunjukkan bahwa kombinasi beberapa model dasar berhasil menurunkan variansi dan membuat prediksi lebih stabil.

* Pada grafik Distribution Comparison, kurva prediksi GPA memiliki bentuk distribusi yang hampir sama dengan distribusi GPA aktual. Overlap yang sangat besar antara keduanya mengindikasikan bahwa model Stacking tidak hanya akurat secara titik per titik, tetapi juga berhasil meniru distribusi keseluruhan data asli. Dengan kata lain, model memahami pola global GPA dengan baik dan tidak menghasilkan prediksi yang terlalu bias ke nilai tertentu.

# Cross Validation
"""

from sklearn.model_selection import KFold, cross_val_score
import numpy as np

def evaluate_with_cv(model, x, y, cv=5):
    kf = KFold(n_splits=cv, shuffle=True, random_state=42)

    mae_scores = -cross_val_score(model, x, y, cv=kf, scoring="neg_mean_absolute_error")
    rmse_scores = np.sqrt(-cross_val_score(model, x, y, cv=kf, scoring="neg_mean_squared_error"))
    r2_scores = cross_val_score(model, x, y, cv=kf, scoring="r2")

    results = {
        "MAE_mean": mae_scores.mean(),
        "MAE_std": mae_scores.std(),
        "RMSE_mean": rmse_scores.mean(),
        "RMSE_std": rmse_scores.std(),
        "R2_mean": r2_scores.mean(),
        "R2_std": r2_scores.std()
    }

    return results

models = {
    "Decision Tree": dt_model,
    "Random Forest": bagging_model,
    "Decision Tree Bagging": bagging_model_dt,
    "Gradient Boosting": gb_model,
    "AdaBoost": ada_model,
    "Stacking": stacking_model
}

cv_results = {}

for name, model in models.items():
    print(f"\nCross Validation: {name}")
    result = evaluate_with_cv(model, x, y)
    cv_results[name] = result

    for metric, value in result.items():
        print(f"{metric}: {value}")

"""**Penjelasan insight:** Berdasarkan hasil output cross validation di atas, diperoleh beberapa insight yaitu sebagai berikut:
1. Berdasarkan hasil cross-validation, model dasar seperti Decision Tree menunjukkan performa paling rendah, terlihat dari MAE dan RMSE yang paling tinggi serta nilai R² yang hanya sekitar 0.89. Ini menandakan bahwa model sederhana ini kurang mampu menangkap pola kompleks pada data, sehingga akurasinya lebih rendah dibanding model lain yang lebih maju. Model ini bisa dijadikan baseline, tetapi jelas bukan pilihan terbaik untuk prediksi yang akurat.

2. Model Random Forest, Bagging, dan AdaBoost memberikan peningkatan performa yang signifikan. Random Forest sudah menunjukkan akurasi yang jauh lebih baik dibanding Decision Tree, kemudian Bagging berhasil memperbaiki hasil tersebut dengan error yang lebih rendah dan R² sekitar 0.94. AdaBoost bahkan sedikit lebih baik lagi, menunjukkan bahwa metode boosting mulai memberikan keunggulan yang jelas dalam meningkatkan kualitas prediksi. Ketiga model ini juga memiliki standar deviasi kecil, sehingga performanya stabil di setiap fold CV.

3. Model dengan performa terbaik adalah Gradient Boosting dan Stacking, yang keduanya menghasilkan MAE dan RMSE paling rendah serta nilai R² tertinggi sekitar 0.958. Artinya, kedua model ini mampu menjelaskan hampir seluruh variansi dalam data dan memberikan prediksi paling akurat serta konsisten. Gradient Boosting menjadi model terbaik secara keseluruhan, sementara Stacking berada pada tingkat performa yang hampir sama, sehingga keduanya merupakan kandidat paling ideal untuk digunakan sebagai model final.
"""

df_results = pd.DataFrame(cv_results).T
df_results_rounded = df_results.round(4)

display(df_results_rounded)

"""**Penjelasan insight:** Hasil evaluasi menunjukkan bahwa model ensemble, khususnya Gradient Boosting dan Stacking, memberikan performa terbaik karena memiliki nilai MAE dan RMSE paling rendah serta R² yang paling tinggi. Artinya, kedua model ini mampu memprediksi dengan error yang kecil dan menjelaskan hampir seluruh variasi data secara akurat. Model seperti AdaBoost dan Decision Tree Bagging juga menunjukkan performa yang cukup baik, meskipun sedikit di bawah dua model terbaik tersebut. Sementara itu, Random Forest masih akurat tetapi tidak sekuat metode boosting, dan Decision Tree menjadi model dengan kinerja terendah. Secara keseluruhan, semakin kompleks metode ensemble yang digunakan, semakin baik akurasi dan stabilitas model dalam memprediksi.

# Final Verdict
"""

def analyze_models(model_tracker, x_test, y_test):
    model_names = []
    maes = []
    rmses = []
    r2s = []
    y_preds = {}

    for name, model in model_tracker.items():
        y_pred = model.predict(x_test)
        y_preds[name] = y_pred

        mae = mean_absolute_error(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        r2 = r2_score(y_test, y_pred)

        model_names.append(name)
        maes.append(mae)
        rmses.append(rmse)
        r2s.append(r2)

    sorted_idx = sorted(range(len(maes)), key=lambda i: maes[i])
    model_names_sorted = [model_names[i] for i in sorted_idx]
    maes_sorted = [maes[i] for i in sorted_idx]
    rmses_sorted = [rmses[i] for i in sorted_idx]
    r2s_sorted = [r2s[i] for i in sorted_idx]

    best_model_name = model_names_sorted[0]
    best_pred = y_preds[best_model_name]

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    ax1, ax2, ax3, ax4 = axes.ravel()

    ax1.bar(model_names_sorted, maes_sorted)
    ax1.set_title("Model Comparison – MAE")
    ax1.set_ylabel("MAE")
    ax1.set_xticklabels(model_names_sorted, rotation=20)
    ax1.grid(axis="y", linestyle="--", alpha=0.4)

    for i, v in enumerate(maes_sorted):
        ax1.text(i, v + 0.002, f"{v:.3f}", ha="center")

    ax2.bar(model_names_sorted, rmses_sorted)
    ax2.set_title("Model Comparison – RMSE")
    ax2.set_ylabel("RMSE")
    ax2.set_xticklabels(model_names_sorted, rotation=20)
    ax2.grid(axis="y", linestyle="--", alpha=0.4)

    for i, v in enumerate(rmses_sorted):
        ax2.text(i, v + 0.002, f"{v:.3f}", ha="center")

    ax3.bar(model_names_sorted, r2s_sorted)
    ax3.set_title("Model Comparison – R² Score")
    ax3.set_ylabel("R²")
    ax3.set_xticklabels(model_names_sorted, rotation=20)
    ax3.grid(axis="y", linestyle="--", alpha=0.4)

    for i, v in enumerate(r2s_sorted):
        ax3.text(i, v + 0.01, f"{v:.3f}", ha="center")

    ax4.scatter(y_test, best_pred, s=20)
    ax4.set_title(f"Prediction vs Actual – Best Model: {best_model_name}")
    ax4.set_xlabel("Actual GPA")
    ax4.set_ylabel("Predicted GPA")
    ax4.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')

    plt.tight_layout()
    plt.show()

model_tracker = {
    "Decision Tree": dt_model,
    "Random Forest": bagging_model,
    "Decision Tree Bagging": bagging_model_dt,
    "Gradient Boosting": gb_model,
    "AdaBoost": ada_model,
    "Stacking": stacking_model
}

analyze_models(model_tracker, x_test, y_test)

"""**Penjelasan insight:** Berdasarkan hasil visualisasi final verdict di atas diperoleh beberapa insight yaitu:
* Grafik MAE dan RMSE menunjukkan bahwa Stacking dan Gradient Boosting merupakan model dengan kesalahan prediksi paling kecil. Nilai MAE dan RMSE yang rendah menandakan bahwa prediksi model sangat mendekati nilai aktual dan jarang melakukan error besar. Sebaliknya, Decision Tree dan Random Forest memiliki error yang lebih tinggi, sehingga performanya lebih lemah dibanding model ensemble yang lebih kompleks.

* Pada grafik R², model Stacking kembali menjadi yang terbaik dengan nilai R² tertinggi, diikuti oleh AdaBoost dan Gradient Boosting. Nilai R² yang tinggi menunjukkan bahwa model mampu menjelaskan sebagian besar variasi data target. Sementara itu, Decision Tree memiliki R² paling rendah, menandakan bahwa model sederhana ini kurang mampu menangkap pola data secara optimal.

* Secara keseluruhan, model-model ensemble seperti Stacking, Boosting, dan Bagging memberikan performa yang jauh lebih baik dibanding pohon keputusan tunggal. Hal ini terlihat dari error yang lebih kecil dan nilai R² yang lebih tinggi, membuktikan bahwa teknik ensemble berhasil menggabungkan kekuatan beberapa model dan menghasilkan prediksi yang lebih stabil dan akurat.

* Grafik Predicted vs Actual dari model Stacking memperlihatkan bahwa titik-titik prediksi tersebar dekat dengan garis merah atau niasa disebut dengan garis ideal, yang berarti model menghasilkan prediksi yang sangat mendekati nilai sebenarnya. Pola penyebaran yang rapat di sepanjang garis menunjukkan tingkat akurasi yang tinggi dan tidak ada pola error tertentu yang mengindikasikan bias sistematis.

Secara keseluruhan, visualisasi menunjukkan bahwa Stacking adalah model paling optimal, disusul oleh Gradient Boosting dan AdaBoost. Model ini mampu memberikan keseimbangan terbaik antara error rendah, akurasi tinggi, dan prediksi yang konsisten. Model sederhana seperti Decision Tree memiliki performa paling rendah karena kurang mampu menangkap kompleksitas data.
"""